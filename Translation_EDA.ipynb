{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Exploration & Data Cleaning\n",
    "Author Brian Tam, 11/02/2020\n",
    "\n",
    "This notebook is used to clean the [Bible corpus](https://www.kaggle.com/oswinrh/bible) as an intermediate setup to prep it for moding.\n",
    "Specifically this initial process explored the different translations and their individual advantages:\n",
    "1. Total vocabulary (for the purposes of dimensionality reduction)\n",
    "2. How true to the original Greek/Hebrew is the translation\n",
    "For a detailed breakdown look [here](https://commonwaychurch.com/wp-content/uploads/2015/11/bibletranslationchart.pdf)\n",
    "\n",
    "There is a huge variety of weird bible versions, includeing [this one](https://www.cnet.com/news/bible-from-a-z-software-rewrites-entire-king-james-version-alphabetically/)\n",
    "\n",
    "Utlimately I decided to use the BBE translation for its inhertly smaller vocabulary that leads to natural dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T00:04:05.441300Z",
     "iopub.status.busy": "2020-11-06T00:04:05.441058Z",
     "iopub.status.idle": "2020-11-06T00:04:05.994287Z",
     "shell.execute_reply": "2020-11-06T00:04:05.993566Z",
     "shell.execute_reply.started": "2020-11-06T00:04:05.441273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Get pandas and postgres to work together\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "# Panda overides for visuals\n",
    "pd.set_option('display.max_colwidth', 1)\n",
    "\n",
    "# Text Preprocessing\n",
    "import re\n",
    "import string\n",
    "# Import spacy to do NLP\n",
    "import spacy\n",
    "parser = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Import sklearn to do CountVectorizing and TF-IDF document-term matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "# Import custom spaCy preprocessing\n",
    "from utilities.text_cleaning import spacy_tokenizer\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding features to classify the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T05:56:05.674659Z",
     "iopub.status.busy": "2020-11-06T05:56:05.674442Z",
     "iopub.status.idle": "2020-11-06T05:56:05.741001Z",
     "shell.execute_reply": "2020-11-06T05:56:05.740351Z",
     "shell.execute_reply.started": "2020-11-06T05:56:05.674634Z"
    }
   },
   "outputs": [],
   "source": [
    "def bible_features(df):\n",
    "    d = {False:'old', True: 'new'}\n",
    "    df['testiment']=(df['field.1']>39).map(d)\n",
    "\n",
    "    # mapping the actual book names field.1\n",
    "    books_of_bible = pd.read_pickle('data/books_of_bible.pkl')\n",
    "    books_dict = dict(zip(range(1,67),books_of_bible))\n",
    "    df['book'] = df['field.1'].map(books_dict)\n",
    "\n",
    "    # chapters\n",
    "    df['chapter'] = df['field.2']\n",
    "\n",
    "    # verse number\n",
    "    df['verse'] = df['field.3']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KJV translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The King James Bible is an English translation of the Christian Bible commissioned for the Church of England in 1604 and completed and published in 1611.\n",
    "- One of the oldest and most well respected versions of the bible\n",
    "- Written in old English (so modern toolkits like Spacy may not filter through the words correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T06:12:51.901829Z",
     "iopub.status.busy": "2020-11-06T06:12:51.901535Z",
     "iopub.status.idle": "2020-11-06T06:12:51.971351Z",
     "shell.execute_reply": "2020-11-06T06:12:51.970641Z",
     "shell.execute_reply.started": "2020-11-06T06:12:51.901804Z"
    }
   },
   "outputs": [],
   "source": [
    "kjv = bible_features(kjv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T00:04:05.999124Z",
     "iopub.status.busy": "2020-11-06T00:04:05.998936Z",
     "iopub.status.idle": "2020-11-06T00:04:06.097635Z",
     "shell.execute_reply": "2020-11-06T00:04:06.097010Z",
     "shell.execute_reply.started": "2020-11-06T00:04:05.999102Z"
    }
   },
   "outputs": [],
   "source": [
    "kjv=pd.read_csv('bible_corpus/bible_databases-master/t_kjv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T05:03:28.243610Z",
     "iopub.status.busy": "2020-11-06T05:03:28.243416Z",
     "iopub.status.idle": "2020-11-06T05:04:27.771412Z",
     "shell.execute_reply": "2020-11-06T05:04:27.770792Z",
     "shell.execute_reply.started": "2020-11-06T05:03:28.243589Z"
    }
   },
   "outputs": [],
   "source": [
    "kjv['cleaner']=kjv['field.4'].apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T05:51:33.226237Z",
     "iopub.status.busy": "2020-11-06T05:51:33.226019Z",
     "iopub.status.idle": "2020-11-06T05:51:33.307239Z",
     "shell.execute_reply": "2020-11-06T05:51:33.306607Z",
     "shell.execute_reply.started": "2020-11-06T05:51:33.226214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>field.1</th>\n",
       "      <th>field.2</th>\n",
       "      <th>field.3</th>\n",
       "      <th>field.4</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>cleaner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16102</th>\n",
       "      <td>19123004</td>\n",
       "      <td>19</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>Our soul is exceedingly filled with the scorning of those that are at ease, and with the contempt of the proud.</td>\n",
       "      <td>soul exceedingly fill scorning ease contempt proud</td>\n",
       "      <td>soul exceedingly fill scorning ease contempt proud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16103</th>\n",
       "      <td>19124001</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>If it had not been the LORD who was on our side, now may Israel say;</td>\n",
       "      <td>lord israel</td>\n",
       "      <td>lord israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16104</th>\n",
       "      <td>19124002</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>If it had not been the LORD who was on our side, when men rose up against us:</td>\n",
       "      <td>lord man rise</td>\n",
       "      <td>lord man rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16105</th>\n",
       "      <td>19124003</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>Then they had swallowed us up quick, when their wrath was kindled against us:</td>\n",
       "      <td>swallow quick wrath kindle</td>\n",
       "      <td>swallow quick wrath kindle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          field  field.1  field.2  field.3  \\\n",
       "16102  19123004  19       123      4         \n",
       "16103  19124001  19       124      1         \n",
       "16104  19124002  19       124      2         \n",
       "16105  19124003  19       124      3         \n",
       "\n",
       "                                                                                                               field.4  \\\n",
       "16102  Our soul is exceedingly filled with the scorning of those that are at ease, and with the contempt of the proud.   \n",
       "16103  If it had not been the LORD who was on our side, now may Israel say;                                              \n",
       "16104  If it had not been the LORD who was on our side, when men rose up against us:                                     \n",
       "16105  Then they had swallowed us up quick, when their wrath was kindled against us:                                     \n",
       "\n",
       "                                                  cleaned  \\\n",
       "16102  soul exceedingly fill scorning ease contempt proud   \n",
       "16103  lord israel                                          \n",
       "16104  lord man rise                                        \n",
       "16105  swallow quick wrath kindle                           \n",
       "\n",
       "                                                  cleaner  \n",
       "16102  soul exceedingly fill scorning ease contempt proud  \n",
       "16103  lord israel                                         \n",
       "16104  lord man rise                                       \n",
       "16105  swallow quick wrath kindle                          "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kjv.iloc[16102:16106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T00:05:16.809721Z",
     "iopub.status.busy": "2020-11-06T00:05:16.809422Z",
     "iopub.status.idle": "2020-11-06T00:05:18.097608Z",
     "shell.execute_reply": "2020-11-06T00:05:18.096394Z",
     "shell.execute_reply.started": "2020-11-06T00:05:16.809670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10114"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf1 = TfidfVectorizer()\n",
    "X_train_tfidf1 = tfidf1.fit_transform(X)\n",
    "len(pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names()).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T00:05:18.099340Z",
     "iopub.status.busy": "2020-11-06T00:05:18.098955Z",
     "iopub.status.idle": "2020-11-06T00:05:18.894952Z",
     "shell.execute_reply": "2020-11-06T00:05:18.893750Z",
     "shell.execute_reply.started": "2020-11-06T00:05:18.099303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaron</th>\n",
       "      <th>aaronites</th>\n",
       "      <th>abaddon</th>\n",
       "      <th>abagtha</th>\n",
       "      <th>abana</th>\n",
       "      <th>abarim</th>\n",
       "      <th>abase</th>\n",
       "      <th>abate</th>\n",
       "      <th>abba</th>\n",
       "      <th>abda</th>\n",
       "      <th>...</th>\n",
       "      <th>zorathites</th>\n",
       "      <th>zoreah</th>\n",
       "      <th>zorites</th>\n",
       "      <th>zorobabel</th>\n",
       "      <th>zuar</th>\n",
       "      <th>zuph</th>\n",
       "      <th>zur</th>\n",
       "      <th>zuriel</th>\n",
       "      <th>zurishaddai</th>\n",
       "      <th>zuzims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31098</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31099</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31100</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31102</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31103 rows × 10114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aaron  aaronites  abaddon  abagtha  abana  abarim  abase  abate  abba  \\\n",
       "0      0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "1      0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "2      0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "3      0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "4      0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "...    ...    ...        ...      ...      ...    ...     ...    ...    ...    \n",
       "31098  0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "31099  0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "31100  0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "31101  0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "31102  0.0    0.0        0.0      0.0      0.0    0.0     0.0    0.0    0.0    \n",
       "\n",
       "       abda  ...  zorathites  zoreah  zorites  zorobabel  zuar  zuph  zur  \\\n",
       "0      0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "1      0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "2      0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "3      0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "4      0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "...    ...   ...  ...         ...     ...      ...        ...   ...   ...   \n",
       "31098  0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "31099  0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "31100  0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "31101  0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "31102  0.0   ...  0.0         0.0     0.0      0.0        0.0   0.0   0.0   \n",
       "\n",
       "       zuriel  zurishaddai  zuzims  \n",
       "0      0.0     0.0          0.0     \n",
       "1      0.0     0.0          0.0     \n",
       "2      0.0     0.0          0.0     \n",
       "3      0.0     0.0          0.0     \n",
       "4      0.0     0.0          0.0     \n",
       "...    ...     ...          ...     \n",
       "31098  0.0     0.0          0.0     \n",
       "31099  0.0     0.0          0.0     \n",
       "31100  0.0     0.0          0.0     \n",
       "31101  0.0     0.0          0.0     \n",
       "31102  0.0     0.0          0.0     \n",
       "\n",
       "[31103 rows x 10114 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBE translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibe in basic English was a translations done by Professor S. H. Hooke following the standards of \"Basic English\", last revised in 1965\n",
    "This implies a couple of restricitons:\n",
    "- Basic English restricts Vocabulary to 1000 words \n",
    "    - 850 base words\n",
    "    - 100 additional words for poetry\n",
    "    - 50 additional words related to biblical context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.268089Z",
     "iopub.status.idle": "2020-11-06T00:05:19.268497Z",
     "shell.execute_reply": "2020-11-06T00:05:19.268329Z"
    }
   },
   "outputs": [],
   "source": [
    "# import the default 850 basic english words \n",
    "basic_english = pd.read_pickle('data/basic_english_list.pkl')\n",
    "len(basic_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.269421Z",
     "iopub.status.idle": "2020-11-06T00:05:19.269746Z",
     "shell.execute_reply": "2020-11-06T00:05:19.269609Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import BBE translation to df\n",
    "bbe = pd.read_csv('bible_corpus/bible_databases-master/t_bbe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.270644Z",
     "iopub.status.idle": "2020-11-06T00:05:19.270998Z",
     "shell.execute_reply": "2020-11-06T00:05:19.270856Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove lemmetize, remove stop-words and punctuation\n",
    "bbe['cleaned']=bbe['field.4'].apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.272055Z",
     "iopub.status.idle": "2020-11-06T00:05:19.272445Z",
     "shell.execute_reply": "2020-11-06T00:05:19.272278Z"
    }
   },
   "outputs": [],
   "source": [
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "bbe['cleaner']= bbe.cleaned.map(alphanumeric).map(punc_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.273707Z",
     "iopub.status.idle": "2020-11-06T00:05:19.274286Z",
     "shell.execute_reply": "2020-11-06T00:05:19.274003Z"
    }
   },
   "outputs": [],
   "source": [
    "bbe.iloc[16102:16106]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.278579Z",
     "iopub.status.idle": "2020-11-06T00:05:19.278955Z",
     "shell.execute_reply": "2020-11-06T00:05:19.278784Z"
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://briantam:localhost@localhost/bible')\n",
    "\n",
    "bbe.to_sql('bbe_alchemy', engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-06T06:13:37.614922Z",
     "iopub.status.busy": "2020-11-06T06:13:37.614692Z",
     "iopub.status.idle": "2020-11-06T06:13:42.850355Z",
     "shell.execute_reply": "2020-11-06T06:13:42.849731Z",
     "shell.execute_reply.started": "2020-11-06T06:13:37.614896Z"
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://briantam:localhost@localhost/bible')\n",
    "\n",
    "kjv.to_sql('kjv', engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.280203Z",
     "iopub.status.idle": "2020-11-06T00:05:19.280520Z",
     "shell.execute_reply": "2020-11-06T00:05:19.280366Z"
    }
   },
   "outputs": [],
   "source": [
    "bbe.to_csv('data/bbe_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NO** stop_words **YES** basic_english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.281627Z",
     "iopub.status.idle": "2020-11-06T00:05:19.282042Z",
     "shell.execute_reply": "2020-11-06T00:05:19.281824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define what you'll feed into the vectorizer as X\n",
    "X = bbe['cleaner']\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "bbe_cleaned_tfidf = tfidf.fit_transform(X)\n",
    "bbe_cleaned_tfidf_df = pd.DataFrame(bbe_cleaned_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "print('Vocab size: ', len(bbe_cleaned_tfidf_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.283248Z",
     "iopub.status.idle": "2020-11-06T00:05:19.283658Z",
     "shell.execute_reply": "2020-11-06T00:05:19.283497Z"
    }
   },
   "outputs": [],
   "source": [
    "mytolkens = parser(' '.join(list(bbe_cleaned_tfidf_df.columns)))\n",
    "tolken_list = [tolken.pos_ for tolken in mytolkens]\n",
    "BBE_POS_df = pd.DataFrame([(x, tolken_list.count(x)) for x in set(tolken_list)]).sort_values(1)\n",
    "plt.barh(BBE_POS_df[0],BBE_POS_df[1])\n",
    "plt.title('Vocab Distribution of BBE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T04:01:37.456509Z",
     "iopub.status.busy": "2020-11-03T04:01:37.456241Z",
     "iopub.status.idle": "2020-11-03T04:01:37.458906Z",
     "shell.execute_reply": "2020-11-03T04:01:37.458338Z",
     "shell.execute_reply.started": "2020-11-03T04:01:37.456484Z"
    }
   },
   "source": [
    "# Trying other stop_word filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NO** stop_words **NO** basic_english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.285181Z",
     "iopub.status.idle": "2020-11-06T00:05:19.285789Z",
     "shell.execute_reply": "2020-11-06T00:05:19.285513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define what you'll feed into the vectorizer as X\n",
    "X = bbe['cleaned']\n",
    "tfidf = TfidfVectorizer(stop_words = basic_english)\n",
    "bbe_cleaned_tfidf = tfidf.fit_transform(X)\n",
    "bbe_cleaned_tfidf = pd.DataFrame(bbe_cleaned_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "print('Vocab size: ', len(bbe_cleaned_tfidf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.287494Z",
     "iopub.status.idle": "2020-11-06T00:05:19.288307Z",
     "shell.execute_reply": "2020-11-06T00:05:19.288022Z"
    }
   },
   "outputs": [],
   "source": [
    "parser = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.290122Z",
     "iopub.status.idle": "2020-11-06T00:05:19.290639Z",
     "shell.execute_reply": "2020-11-06T00:05:19.290378Z"
    }
   },
   "outputs": [],
   "source": [
    "mytolkens = parser(' '.join(list(bbe_cleaned_tfidf.columns)))\n",
    "tolken_list = [tolken.pos_ for tolken in mytolkens]\n",
    "BBE_POS_df = pd.DataFrame([(x, tolken_list.count(x)) for x in set(tolken_list)]).sort_values(1)\n",
    "plt.barh(BBE_POS_df[0],BBE_POS_df[1])\n",
    "plt.title('Vocab Distribution of BBE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **YES** stop_words **NO** basic_english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.292164Z",
     "iopub.status.idle": "2020-11-06T00:05:19.293142Z",
     "shell.execute_reply": "2020-11-06T00:05:19.292813Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define what you'll feed into the vectorizer as X\n",
    "X = bbe['cleaned']\n",
    "tfidf = TfidfVectorizer(max_df=.9 stop_words = basic_english)\n",
    "X_train_tfidf1 = tfidf1.fit_transform(X)\n",
    "\n",
    "len(pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names()).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.294637Z",
     "iopub.status.idle": "2020-11-06T00:05:19.295006Z",
     "shell.execute_reply": "2020-11-06T00:05:19.294817Z"
    }
   },
   "outputs": [],
   "source": [
    "bbe_tfidf = pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.297300Z",
     "iopub.status.idle": "2020-11-06T00:05:19.297851Z",
     "shell.execute_reply": "2020-11-06T00:05:19.297584Z"
    }
   },
   "outputs": [],
   "source": [
    "mytolkens = parser(' '.join(list(bbe_tfidf.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.299061Z",
     "iopub.status.idle": "2020-11-06T00:05:19.299369Z",
     "shell.execute_reply": "2020-11-06T00:05:19.299221Z"
    }
   },
   "outputs": [],
   "source": [
    "tolken_list = [tolken.pos_ for tolken in mytolkens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.300952Z",
     "iopub.status.idle": "2020-11-06T00:05:19.301290Z",
     "shell.execute_reply": "2020-11-06T00:05:19.301130Z"
    }
   },
   "outputs": [],
   "source": [
    "BBE_POS_df = pd.DataFrame([(x, tolken_list.count(x)) for x in set(tolken_list)]).sort_values(1)\n",
    "BBE_POS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.302956Z",
     "iopub.status.idle": "2020-11-06T00:05:19.303617Z",
     "shell.execute_reply": "2020-11-06T00:05:19.303355Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.barh(BBE_POS_df[0],BBE_POS_df[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **YES** stop_words **YES** basic_english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.305728Z",
     "iopub.status.idle": "2020-11-06T00:05:19.306775Z",
     "shell.execute_reply": "2020-11-06T00:05:19.305993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define what you'll feed into the vectorizer as X\n",
    "X = bbe['field.4']\n",
    "tfidf = TfidfVectorizer()\n",
    "bbe_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "print('Vocab Size: ', len(pd.DataFrame(bbe_tfidf.toarray(), columns=tfidf.get_feature_names()).columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.311477Z",
     "iopub.status.idle": "2020-11-06T00:05:19.311833Z",
     "shell.execute_reply": "2020-11-06T00:05:19.311671Z"
    }
   },
   "outputs": [],
   "source": [
    "bbe_tfidf = pd.DataFrame(bbe_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "mytolkens = parser(' '.join(list(bbe_tfidf.columns)))\n",
    "tolken_list = [tolken.pos_ for tolken in mytolkens]\n",
    "BBE_POS_df = pd.DataFrame([(x, tolken_list.count(x)) for x in set(tolken_list)]).sort_values(1)\n",
    "plt.barh(BBE_POS_df[0],BBE_POS_df[1])\n",
    "plt.title('Vocab Distribution of BBE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.314115Z",
     "iopub.status.idle": "2020-11-06T00:05:19.314608Z",
     "shell.execute_reply": "2020-11-06T00:05:19.314403Z"
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "text = ' '.join([tolken.pos_ for tolken in mytolkens])\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(width = 1000, height = 1000,\n",
    "                background_color =\"rgba(255, 255, 255, 0)\", mode=\"RGBA\").generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(f'POS_BBE_not_in_BE.png',bbox_inches = 'tight', pad_inches = .25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T05:44:17.954822Z",
     "iopub.status.busy": "2020-11-01T05:44:17.954592Z",
     "iopub.status.idle": "2020-11-01T05:44:17.957612Z",
     "shell.execute_reply": "2020-11-01T05:44:17.956743Z",
     "shell.execute_reply.started": "2020-11-01T05:44:17.954797Z"
    }
   },
   "source": [
    "### WEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.316420Z",
     "iopub.status.idle": "2020-11-06T00:05:19.316975Z",
     "shell.execute_reply": "2020-11-06T00:05:19.316676Z"
    }
   },
   "outputs": [],
   "source": [
    "web = pd.read_csv('data/bible_databases-master/t_web.csv')\n",
    "# Assign the \n",
    "X = web['field.4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2020-11-06T00:05:19.318238Z",
     "iopub.status.idle": "2020-11-06T00:05:19.318716Z",
     "shell.execute_reply": "2020-11-06T00:05:19.318501Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create TF-IDF of the array of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X)\n",
    "len(pd.DataFrame(X_train_tfidf.toarray(), columns=tfidf.get_feature_names()).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T06:01:22.928522Z",
     "iopub.status.busy": "2020-11-01T06:01:22.928328Z",
     "iopub.status.idle": "2020-11-01T06:01:22.930897Z",
     "shell.execute_reply": "2020-11-01T06:01:22.930215Z",
     "shell.execute_reply.started": "2020-11-01T06:01:22.928501Z"
    }
   },
   "source": [
    "### WBT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YLT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
