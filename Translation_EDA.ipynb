{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation Exploration & Data Cleaning\n",
    "Author Brian Tam, 11/02/2020\n",
    "\n",
    "This notebook is used to clean the [Bible corpus](https://www.kaggle.com/oswinrh/bible) as an intermediate setup to prep it for moding.\n",
    "Specifically this initial process explored the different translations and their individual advantages:\n",
    "1. Total vocabulary (for the purposes of dimensionality reduction)\n",
    "2. How true to the original Greek/Hebrew is the translation\n",
    "For a detailed breakdown look [here](https://commonwaychurch.com/wp-content/uploads/2015/11/bibletranslationchart.pdf)\n",
    "\n",
    "There is a huge variety of weird bible versions, includeing [this one](https://www.cnet.com/news/bible-from-a-z-software-rewrites-entire-king-james-version-alphabetically/)\n",
    "\n",
    "Utlimately I decided to use the BBE translation for its inhertly smaller vocabulary that leads to natural dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T04:55:56.027704Z",
     "iopub.status.busy": "2020-11-05T04:55:56.023118Z",
     "iopub.status.idle": "2020-11-05T04:56:08.724620Z",
     "shell.execute_reply": "2020-11-05T04:56:08.724044Z",
     "shell.execute_reply.started": "2020-11-05T04:55:56.027103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get pandas and postgres to work together\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "# Panda overides for visuals\n",
    "pd.set_option('display.max_colwidth', 1)\n",
    "\n",
    "# Text Preprocessing\n",
    "import re\n",
    "import string\n",
    "# Import spacy to do NLP\n",
    "import spacy\n",
    "parser = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Import sklearn to do CountVectorizing and TF-IDF document-term matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "# Import custom spaCy preprocessing\n",
    "from utilities.text_cleaning import spacy_tokenizer\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KJV translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The King James Bible is an English translation of the Christian Bible commissioned for the Church of England in 1604 and completed and published in 1611.\n",
    "- One of the oldest and most well respected versions of the bible\n",
    "- Written in old English (so modern toolkits like Spacy may not filter through the words correctly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kjv=pd.read_csv('bible_corpus/bible_databases-master/t_kjv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kjv['cleaned']=kjv['field.4'].apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y data sets\n",
    "X = kjv.cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf1 = TfidfVectorizer()\n",
    "X_train_tfidf1 = tfidf1.fit_transform(X)\n",
    "len(pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names()).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acronynms: Latent Semantic Analysis (LSA) is just another name for \n",
    "#  Signular Value Decomposition (SVD) applied to Natural Language Processing (NLP)\n",
    "\n",
    "TopicModel = NMF(10)\n",
    "doc_topic = TopicModel.fit_transform(pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = display_topics(TopicModel, tfidf1.get_feature_names(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_word = pd.DataFrame(TopicModel.components_.round(3),\n",
    "             index =  topics,\n",
    "             columns = tfidf1.get_feature_names())\n",
    "topic_word.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_topic_array = TopicModel.transform(pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_topics = pd.DataFrame(doc_topic.round(5),\n",
    "             index = X.index,\n",
    "             columns = topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_topics.values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBE translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibe in basic English was a translations done by Professor S. H. Hooke following the standards of \"Basic English\", last revised in 1965\n",
    "This implies a couple of restricitons:\n",
    "- Basic English restricts Vocabulary to 1000 words \n",
    "    - 850 base words\n",
    "    - 100 additional words for poetry\n",
    "    - 50 additional words related to biblical context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T04:56:20.150828Z",
     "iopub.status.busy": "2020-11-05T04:56:20.150598Z",
     "iopub.status.idle": "2020-11-05T04:56:20.192088Z",
     "shell.execute_reply": "2020-11-05T04:56:20.191433Z",
     "shell.execute_reply.started": "2020-11-05T04:56:20.150803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the default 850 basic english words \n",
    "basic_english = pd.read_pickle('data/basic_english_list.pkl')\n",
    "len(basic_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T04:56:20.641291Z",
     "iopub.status.busy": "2020-11-05T04:56:20.641068Z",
     "iopub.status.idle": "2020-11-05T04:56:20.738955Z",
     "shell.execute_reply": "2020-11-05T04:56:20.738219Z",
     "shell.execute_reply.started": "2020-11-05T04:56:20.641266Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import BBE translation to df\n",
    "bbe = pd.read_csv('bible_corpus/bible_databases-master/t_bbe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T04:56:21.038448Z",
     "iopub.status.busy": "2020-11-05T04:56:21.038120Z",
     "iopub.status.idle": "2020-11-05T05:00:16.555043Z",
     "shell.execute_reply": "2020-11-05T05:00:16.554426Z",
     "shell.execute_reply.started": "2020-11-05T04:56:21.038417Z"
    }
   },
   "outputs": [],
   "source": [
    "#remove lemmetize, remove stop-words and punctuation\n",
    "bbe['cleaned']=bbe['field.4'].apply(spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T05:00:16.556664Z",
     "iopub.status.busy": "2020-11-05T05:00:16.556465Z",
     "iopub.status.idle": "2020-11-05T05:00:16.717816Z",
     "shell.execute_reply": "2020-11-05T05:00:16.717280Z",
     "shell.execute_reply.started": "2020-11-05T05:00:16.556640Z"
    }
   },
   "outputs": [],
   "source": [
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "bbe['cleaner']= bbe.cleaned.map(punc_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T05:00:16.719619Z",
     "iopub.status.busy": "2020-11-05T05:00:16.719444Z",
     "iopub.status.idle": "2020-11-05T05:00:16.759194Z",
     "shell.execute_reply": "2020-11-05T05:00:16.758564Z",
     "shell.execute_reply.started": "2020-11-05T05:00:16.719598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>field.1</th>\n",
       "      <th>field.2</th>\n",
       "      <th>field.3</th>\n",
       "      <th>field.4</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>cleaner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16102</th>\n",
       "      <td>19123004</td>\n",
       "      <td>19</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>For long enough have men of pride made sport of our soul.</td>\n",
       "      <td>long man pride sport soul</td>\n",
       "      <td>long man pride sport soul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16103</th>\n",
       "      <td>19124001</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;lt;A Song of the going up. Of David.&amp;gt; If it had not been the Lord who was on our side (let Israel now say);</td>\n",
       "      <td>lt;a song david.&amp;gt lord let israel</td>\n",
       "      <td>lt a song david  gt lord let israel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16104</th>\n",
       "      <td>19124002</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>2</td>\n",
       "      <td>If it had not been the Lord who was on our side, when men came up against us;</td>\n",
       "      <td>lord man come</td>\n",
       "      <td>lord man come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16105</th>\n",
       "      <td>19124003</td>\n",
       "      <td>19</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>They would have made a meal of us while still living, in the heat of their wrath against us:</td>\n",
       "      <td>meal live heat wrath</td>\n",
       "      <td>meal live heat wrath</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          field  field.1  field.2  field.3  \\\n",
       "16102  19123004  19       123      4         \n",
       "16103  19124001  19       124      1         \n",
       "16104  19124002  19       124      2         \n",
       "16105  19124003  19       124      3         \n",
       "\n",
       "                                                                                                               field.4  \\\n",
       "16102  For long enough have men of pride made sport of our soul.                                                         \n",
       "16103  &lt;A Song of the going up. Of David.&gt; If it had not been the Lord who was on our side (let Israel now say);   \n",
       "16104  If it had not been the Lord who was on our side, when men came up against us;                                     \n",
       "16105  They would have made a meal of us while still living, in the heat of their wrath against us:                      \n",
       "\n",
       "                                   cleaned  \\\n",
       "16102  long man pride sport soul             \n",
       "16103  lt;a song david.&gt lord let israel   \n",
       "16104  lord man come                         \n",
       "16105  meal live heat wrath                  \n",
       "\n",
       "                                   cleaner  \n",
       "16102  long man pride sport soul            \n",
       "16103  lt a song david  gt lord let israel  \n",
       "16104  lord man come                        \n",
       "16105  meal live heat wrath                 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbe.iloc[16102:16106]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding features to classify the texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T08:26:46.291022Z",
     "iopub.status.busy": "2020-11-05T08:26:46.290821Z",
     "iopub.status.idle": "2020-11-05T08:26:46.348932Z",
     "shell.execute_reply": "2020-11-05T08:26:46.348318Z",
     "shell.execute_reply.started": "2020-11-05T08:26:46.290999Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {False:'old', True: 'new'}\n",
    "bbe['testiment']=(bbe['field.1']>39).map(d)\n",
    "\n",
    "# mapping the actual book names field.1\n",
    "books_of_bible = pd.read_pickle('data/books_of_bible.pkl')\n",
    "books_dict = dict(zip(range(1,67),books_of_bible))\n",
    "bbe['book'] = bbe['field.1'].map(books_dict)\n",
    "\n",
    "# chapters\n",
    "bbe['chapter'] = bbe['field.2']\n",
    "\n",
    "# verse number\n",
    "bbe['verse'] = bbe['field.3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T08:26:47.614859Z",
     "iopub.status.busy": "2020-11-05T08:26:47.614651Z",
     "iopub.status.idle": "2020-11-05T08:26:47.659345Z",
     "shell.execute_reply": "2020-11-05T08:26:47.658744Z",
     "shell.execute_reply.started": "2020-11-05T08:26:47.614836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>field.1</th>\n",
       "      <th>field.2</th>\n",
       "      <th>field.3</th>\n",
       "      <th>field.4</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>cleaner</th>\n",
       "      <th>book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>verse</th>\n",
       "      <th>testiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>At the first God made the heaven and the earth.</td>\n",
       "      <td>god heaven earth</td>\n",
       "      <td>god heaven earth</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001002</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>And the earth was waste and without form; and it was dark on the face of the deep: and the Spirit of God was moving on the face of the waters.</td>\n",
       "      <td>earth waste form dark face deep spirit god face water</td>\n",
       "      <td>earth waste form dark face deep spirit god face water</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>And God said, Let there be light: and there was light.</td>\n",
       "      <td>god let light light</td>\n",
       "      <td>god let light light</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001004</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>And God, looking on the light, saw that it was good: and God made a division between the light and the dark,</td>\n",
       "      <td>god look light good god division light dark</td>\n",
       "      <td>god look light good god division light dark</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Naming the light, Day, and the dark, Night. And there was evening and there was morning, the first day.</td>\n",
       "      <td>light day dark night evening morning day</td>\n",
       "      <td>light day dark night evening morning day</td>\n",
       "      <td>Genesis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31098</th>\n",
       "      <td>66022017</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>And the Spirit and the bride say, Come. And let him who gives ear, say, Come. And let him who is in need come; and let everyone desiring it take of the water of life freely.</td>\n",
       "      <td>spirit bride come let ear come let need come let desire water life freely</td>\n",
       "      <td>spirit bride come let ear come let need come let desire water life freely</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31099</th>\n",
       "      <td>66022018</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>For I say to every man to whose ears have come the words of this prophet's book, If any man makes an addition to them, God will put on him the punishments which are in this book:</td>\n",
       "      <td>man ear come word prophet book man addition god punishment book</td>\n",
       "      <td>man ear come word prophet book man addition god punishment book</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31100</th>\n",
       "      <td>66022019</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>And if any man takes away from the words of this book, God will take away from him his part in the tree of life and the holy town, even the things which are in this book.</td>\n",
       "      <td>man away word book god away tree life holy town thing book</td>\n",
       "      <td>man away word book god away tree life holy town thing book</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31101</th>\n",
       "      <td>66022020</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>He who gives witness to these things says, Truly, I come quickly. Even so come, Lord Jesus.</td>\n",
       "      <td>witness thing truly come quickly come lord jesus</td>\n",
       "      <td>witness thing truly come quickly come lord jesus</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31102</th>\n",
       "      <td>66022021</td>\n",
       "      <td>66</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>The grace of the Lord Jesus be with the saints. So be it.</td>\n",
       "      <td>grace lord jesus saint</td>\n",
       "      <td>grace lord jesus saint</td>\n",
       "      <td>Revelation</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>new</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31103 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          field  field.1  field.2  field.3  \\\n",
       "0      1001001   1        1        1         \n",
       "1      1001002   1        1        2         \n",
       "2      1001003   1        1        3         \n",
       "3      1001004   1        1        4         \n",
       "4      1001005   1        1        5         \n",
       "...        ...  ..       ..       ..         \n",
       "31098  66022017  66       22       17        \n",
       "31099  66022018  66       22       18        \n",
       "31100  66022019  66       22       19        \n",
       "31101  66022020  66       22       20        \n",
       "31102  66022021  66       22       21        \n",
       "\n",
       "                                                                                                                                                                                  field.4  \\\n",
       "0      At the first God made the heaven and the earth.                                                                                                                                      \n",
       "1      And the earth was waste and without form; and it was dark on the face of the deep: and the Spirit of God was moving on the face of the waters.                                       \n",
       "2      And God said, Let there be light: and there was light.                                                                                                                               \n",
       "3      And God, looking on the light, saw that it was good: and God made a division between the light and the dark,                                                                         \n",
       "4      Naming the light, Day, and the dark, Night. And there was evening and there was morning, the first day.                                                                              \n",
       "...                                                                                                        ...                                                                              \n",
       "31098  And the Spirit and the bride say, Come. And let him who gives ear, say, Come. And let him who is in need come; and let everyone desiring it take of the water of life freely.        \n",
       "31099  For I say to every man to whose ears have come the words of this prophet's book, If any man makes an addition to them, God will put on him the punishments which are in this book:   \n",
       "31100  And if any man takes away from the words of this book, God will take away from him his part in the tree of life and the holy town, even the things which are in this book.           \n",
       "31101  He who gives witness to these things says, Truly, I come quickly. Even so come, Lord Jesus.                                                                                          \n",
       "31102  The grace of the Lord Jesus be with the saints. So be it.                                                                                                                            \n",
       "\n",
       "                                                                         cleaned  \\\n",
       "0      god heaven earth                                                            \n",
       "1      earth waste form dark face deep spirit god face water                       \n",
       "2      god let light light                                                         \n",
       "3      god look light good god division light dark                                 \n",
       "4      light day dark night evening morning day                                    \n",
       "...                                         ...                                    \n",
       "31098  spirit bride come let ear come let need come let desire water life freely   \n",
       "31099  man ear come word prophet book man addition god punishment book             \n",
       "31100  man away word book god away tree life holy town thing book                  \n",
       "31101  witness thing truly come quickly come lord jesus                            \n",
       "31102  grace lord jesus saint                                                      \n",
       "\n",
       "                                                                         cleaner  \\\n",
       "0      god heaven earth                                                            \n",
       "1      earth waste form dark face deep spirit god face water                       \n",
       "2      god let light light                                                         \n",
       "3      god look light good god division light dark                                 \n",
       "4      light day dark night evening morning day                                    \n",
       "...                                         ...                                    \n",
       "31098  spirit bride come let ear come let need come let desire water life freely   \n",
       "31099  man ear come word prophet book man addition god punishment book             \n",
       "31100  man away word book god away tree life holy town thing book                  \n",
       "31101  witness thing truly come quickly come lord jesus                            \n",
       "31102  grace lord jesus saint                                                      \n",
       "\n",
       "             book  chapter  verse testiment  \n",
       "0      Genesis     1        1      old       \n",
       "1      Genesis     1        2      old       \n",
       "2      Genesis     1        3      old       \n",
       "3      Genesis     1        4      old       \n",
       "4      Genesis     1        5      old       \n",
       "...        ...    ..       ..      ...       \n",
       "31098  Revelation  22       17     new       \n",
       "31099  Revelation  22       18     new       \n",
       "31100  Revelation  22       19     new       \n",
       "31101  Revelation  22       20     new       \n",
       "31102  Revelation  22       21     new       \n",
       "\n",
       "[31103 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T08:27:11.704248Z",
     "iopub.status.busy": "2020-11-05T08:27:11.703968Z",
     "iopub.status.idle": "2020-11-05T08:27:15.056848Z",
     "shell.execute_reply": "2020-11-05T08:27:15.056223Z",
     "shell.execute_reply.started": "2020-11-05T08:27:11.704211Z"
    }
   },
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://briantam:localhost@localhost/bible')\n",
    "\n",
    "bbe.to_sql('bbe_alchemy', engine, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T05:00:16.760404Z",
     "iopub.status.busy": "2020-11-05T05:00:16.760220Z",
     "iopub.status.idle": "2020-11-05T05:00:17.000103Z",
     "shell.execute_reply": "2020-11-05T05:00:16.999437Z",
     "shell.execute_reply.started": "2020-11-05T05:00:16.760384Z"
    }
   },
   "outputs": [],
   "source": [
    "bbe.to_csv('data/bbe_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NO** stop_words **YES** basic_english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what you'll feed into the vectorizer as X\n",
    "X = bbe['cleaner']\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "bbe_cleaned_tfidf = tfidf.fit_transform(X)\n",
    "bbe_cleaned_tfidf_df = pd.DataFrame(bbe_cleaned_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "print('Vocab size: ', len(bbe_cleaned_tfidf_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytolkens = parser(' '.join(list(bbe_cleaned_tfidf_df.columns)))\n",
    "tolken_list = [tolken.pos_ for tolken in mytolkens]\n",
    "BBE_POS_df = pd.DataFrame([(x, tolken_list.count(x)) for x in set(tolken_list)]).sort_values(1)\n",
    "plt.barh(BBE_POS_df[0],BBE_POS_df[1])\n",
    "plt.title('Vocab Distribution of BBE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-03T04:01:37.456509Z",
     "iopub.status.busy": "2020-11-03T04:01:37.456241Z",
     "iopub.status.idle": "2020-11-03T04:01:37.458906Z",
     "shell.execute_reply": "2020-11-03T04:01:37.458338Z",
     "shell.execute_reply.started": "2020-11-03T04:01:37.456484Z"
    }
   },
   "source": [
    "# Trying other stop_word filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NO** stop_words **NO** basic_english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what you'll feed into the vectorizer as X\n",
    "X = bbe['cleaned']\n",
    "tfidf = TfidfVectorizer(stop_words = basic_english)\n",
    "bbe_cleaned_tfidf = tfidf.fit_transform(X)\n",
    "bbe_cleaned_tfidf = pd.DataFrame(bbe_cleaned_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "print('Vocab size: ', len(bbe_cleaned_tfidf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytolkens = parser(' '.join(list(bbe_cleaned_tfidf.columns)))\n",
    "tolken_list = [tolken.pos_ for tolken in mytolkens]\n",
    "BBE_POS_df = pd.DataFrame([(x, tolken_list.count(x)) for x in set(tolken_list)]).sort_values(1)\n",
    "plt.barh(BBE_POS_df[0],BBE_POS_df[1])\n",
    "plt.title('Vocab Distribution of BBE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **YES** stop_words **NO** basic_english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what you'll feed into the vectorizer as X\n",
    "X = bbe['cleaned']\n",
    "tfidf = TfidfVectorizer(max_df=.9 stop_words = basic_english)\n",
    "X_train_tfidf1 = tfidf1.fit_transform(X)\n",
    "\n",
    "len(pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names()).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_tfidf = pd.DataFrame(X_train_tfidf1.toarray(), columns=tfidf1.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytolkens = parser(' '.join(list(bbe_tfidf.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolken_list = [tolken.pos_ for tolken in mytolkens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BBE_POS_df = pd.DataFrame([(x, tolken_list.count(x)) for x in set(tolken_list)]).sort_values(1)\n",
    "BBE_POS_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(BBE_POS_df[0],BBE_POS_df[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **YES** stop_words **YES** basic_english "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define what you'll feed into the vectorizer as X\n",
    "X = bbe['field.4']\n",
    "tfidf = TfidfVectorizer()\n",
    "bbe_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "print('Vocab Size: ', len(pd.DataFrame(bbe_tfidf.toarray(), columns=tfidf.get_feature_names()).columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbe_tfidf = pd.DataFrame(bbe_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "mytolkens = parser(' '.join(list(bbe_tfidf.columns)))\n",
    "tolken_list = [tolken.pos_ for tolken in mytolkens]\n",
    "BBE_POS_df = pd.DataFrame([(x, tolken_list.count(x)) for x in set(tolken_list)]).sort_values(1)\n",
    "plt.barh(BBE_POS_df[0],BBE_POS_df[1])\n",
    "plt.title('Vocab Distribution of BBE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordClouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "text = ' '.join([tolken.pos_ for tolken in mytolkens])\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(width = 1000, height = 1000,\n",
    "                background_color =\"rgba(255, 255, 255, 0)\", mode=\"RGBA\").generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "# the matplotlib way:\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(f'POS_BBE_not_in_BE.png',bbox_inches = 'tight', pad_inches = .25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T05:44:17.954822Z",
     "iopub.status.busy": "2020-11-01T05:44:17.954592Z",
     "iopub.status.idle": "2020-11-01T05:44:17.957612Z",
     "shell.execute_reply": "2020-11-01T05:44:17.956743Z",
     "shell.execute_reply.started": "2020-11-01T05:44:17.954797Z"
    }
   },
   "source": [
    "### WEB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web = pd.read_csv('data/bible_databases-master/t_web.csv')\n",
    "# Assign the \n",
    "X = web['field.4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF of the array of words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X)\n",
    "len(pd.DataFrame(X_train_tfidf.toarray(), columns=tfidf.get_feature_names()).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-01T06:01:22.928522Z",
     "iopub.status.busy": "2020-11-01T06:01:22.928328Z",
     "iopub.status.idle": "2020-11-01T06:01:22.930897Z",
     "shell.execute_reply": "2020-11-01T06:01:22.930215Z",
     "shell.execute_reply.started": "2020-11-01T06:01:22.928501Z"
    }
   },
   "source": [
    "### WBT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YLT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
